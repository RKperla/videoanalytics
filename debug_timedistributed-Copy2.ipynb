{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import random\n",
    "import pprint\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import pickle\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras_frcnn import config, data_generators\n",
    "from keras_frcnn import losses as losses\n",
    "import keras_frcnn.roi_helpers as roi_helpers\n",
    "from keras.utils import generic_utils\n",
    "from keras_frcnn.mylayer import mylayer\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "\n",
    "K.set_learning_phase(1) #set learning phase\n",
    "\n",
    "# sys.setrecursionlimit(40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "network ='vgg'\n",
    "\n",
    "if network == 'vgg':\n",
    "\tfrom keras_frcnn import vgg as nn\n",
    "elif network == 'resnet50':\n",
    "\tfrom keras_frcnn import resnet as nn\n",
    "else:\n",
    "\tprint('Not a valid model')\n",
    "\traise ValueError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Tensor(\"mylayer_1/Reshape:0\", shape=(1, 6, 7, 7, 512), dtype=float32)\n",
      "WARNING:tensorflow:From /anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "no of classes 575\n",
      "Could not load pretrained model weights. Weights can be found in the keras application folder \t\thttps://github.com/fchollet/keras/tree/master/keras/applications\n"
     ]
    }
   ],
   "source": [
    "from keras_frcnn.RoiPoolingConv import RoiPoolingConv\n",
    "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, TimeDistributed\n",
    "from keras.layers import Flatten, Dense, Input, Conv2D, MaxPooling2D, Dropout\n",
    "\n",
    "if K.image_dim_ordering() == 'th':\n",
    "\tinput_shape_img = (3, None, None)\n",
    "else:\n",
    "\tinput_shape_img = (400, 400, 3)\n",
    "\n",
    "img_input = Input(shape=input_shape_img)\n",
    "roi_input = Input(shape=(6, 4))\n",
    "nb_classes = 575\n",
    "\n",
    "#pdb.set_trace()\n",
    "num_rois = 6\n",
    "# compile times on theano tend to be very high, so we use smaller ROI pooling regions to workaround\n",
    "\n",
    "if K.backend() == 'tensorflow':\n",
    "    pooling_regions = 7\n",
    "    input_shape = (num_rois,7,7,512)\n",
    "elif K.backend() == 'theano':\n",
    "    pooling_regions = 7\n",
    "    input_shape = (num_rois,512,7,7)\n",
    "\n",
    "# define the base network (resnet here, can be VGG, Inception, etc)\n",
    "shared_layers = nn.nn_base(img_input, trainable=True)\n",
    "\n",
    "\n",
    "out_roi_pool = mylayer(pooling_regions, 6)([shared_layers, roi_input])\n",
    "print out_roi_pool\n",
    "\n",
    "out = (Flatten(name='flatten'))(out_roi_pool)\n",
    "out = (Dense(4096, activation='relu', name='fc1'))(out)\n",
    "out = (Dropout(0.5))(out)\n",
    "out = (Dense(2048, activation='relu', name='fc2'))(out)\n",
    "out = (Dropout(0.5))(out)\n",
    "print 'no of classes', nb_classes\n",
    "out_class = (Dense(166, activation='sigmoid', kernel_initializer='zero'))(out)\n",
    "\n",
    "model_classifier = Model([img_input, roi_input], out_class)\n",
    "\n",
    "\n",
    "try:\n",
    "\tprint('loading weights from {}'.format(C.base_net_weights))\n",
    "\tmodel_classifier.load_weights(C.base_net_weights, by_name=True)\n",
    "except:\n",
    "\tprint('Could not load pretrained model weights. Weights can be found in the keras application folder \\\n",
    "\t\thttps://github.com/fchollet/keras/tree/master/keras/applications')\n",
    "\n",
    "optimizer = Adam(lr=1e-5)\n",
    "optimizer_classifier = Adam(lr=1e-5)\n",
    "model_classifier.compile(optimizer=optimizer_classifier, loss = 'binary_crossentropy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name(x):\n",
    "    name = str.split(x,'/')\n",
    "    return '/Users/1024329/Downloads/DeepFashion/img_n/' + name[1] + '/' + name[2]\n",
    "    \n",
    "df3 = pd.read_pickle('upper_body_atts.pkl')\n",
    "df3['img_name'] = df3['img_name'].apply(lambda x:name(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = []\n",
    "landmarks = []\n",
    "attribs = []\n",
    "for i in range(100):\n",
    "    #print i\n",
    "    a = cv2.imread(df3.loc[i,'img_name'])\n",
    "    a = cv2.resize(a,(400,400))\n",
    "    img.append(a)\n",
    "    lnd = df3.loc[i,'landmarks']\n",
    "    landmarks.append(lnd)\n",
    "    atts = df3.loc[i,'atts']\n",
    "    attribs.append(atts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>img_name</th>\n",
       "      <th>landmarks</th>\n",
       "      <th>atts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24870</td>\n",
       "      <td>29</td>\n",
       "      <td>45</td>\n",
       "      <td>76</td>\n",
       "      <td>21</td>\n",
       "      <td>68.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>63</td>\n",
       "      <td>67</td>\n",
       "      <td>124.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>92</td>\n",
       "      <td>137</td>\n",
       "      <td>/Users/1024329/Downloads/DeepFashion/img_n/Lon...</td>\n",
       "      <td>[[96, 2, 60, 60], [165, 2, 60, 60], [300, 153,...</td>\n",
       "      <td>[99, 495, 571, 881, 940]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106141</td>\n",
       "      <td>53</td>\n",
       "      <td>112</td>\n",
       "      <td>22</td>\n",
       "      <td>130</td>\n",
       "      <td>44.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>122</td>\n",
       "      <td>137</td>\n",
       "      <td>191.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>157</td>\n",
       "      <td>216</td>\n",
       "      <td>/Users/1024329/Downloads/DeepFashion/img_n/Hoo...</td>\n",
       "      <td>[[105, 5, 60, 60], [255, 3, 60, 60], [26, 195,...</td>\n",
       "      <td>[470, 953]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  x1   x2  x3   x4    x5     x6  y1  y2   y3   y4     y5     y6  \\\n",
       "0       24870  29   45  76   21  68.0   13.0  11  11   63   67  124.0  121.0   \n",
       "1      106141  53  112  22  130  44.0  117.0  19  18  122  137  191.0  195.0   \n",
       "\n",
       "     w    h                                           img_name  \\\n",
       "0   92  137  /Users/1024329/Downloads/DeepFashion/img_n/Lon...   \n",
       "1  157  216  /Users/1024329/Downloads/DeepFashion/img_n/Hoo...   \n",
       "\n",
       "                                           landmarks                      atts  \n",
       "0  [[96, 2, 60, 60], [165, 2, 60, 60], [300, 153,...  [99, 495, 571, 881, 940]  \n",
       "1  [[105, 5, 60, 60], [255, 3, 60, 60], [26, 195,...                [470, 953]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes of input and output (100, 400, 400, 3) (100, 6, 4) (100, 166)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "X = np.array(img)\n",
    "X2 = np.array(landmarks)\n",
    "Y = mlb.fit_transform(attribs)\n",
    "X2 = (X2/4).astype(int)\n",
    "print 'shapes of input and output', X.shape, X2.shape, Y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='max', period=1)\n",
    "model_classifier.fit(x = [X,X2],y= Y, batch_size=1, epochs=2,validation_split=0.2,callbacks = [checkpoint])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
