{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import random\n",
    "import pprint\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import pickle\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras_frcnn import config, data_generators\n",
    "from keras_frcnn import losses as losses\n",
    "import keras_frcnn.roi_helpers as roi_helpers\n",
    "from keras.utils import generic_utils\n",
    "from keras_frcnn.mylayer import mylayer\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "\n",
    "K.set_learning_phase(1) #set learning phase\n",
    "\n",
    "# sys.setrecursionlimit(40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "network ='vgg'\n",
    "\n",
    "if network == 'vgg':\n",
    "\tfrom keras_frcnn import vgg as nn\n",
    "elif network == 'resnet50':\n",
    "\tfrom keras_frcnn import resnet as nn\n",
    "else:\n",
    "\tprint('Not a valid model')\n",
    "\traise ValueError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Tensor(\"mylayer_1/Reshape:0\", shape=(1, 6, 4, 4, 512), dtype=float32)\n",
      "WARNING:tensorflow:From /anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "loading weights from pretrained model\n"
     ]
    }
   ],
   "source": [
    "from keras_frcnn.RoiPoolingConv import RoiPoolingConv\n",
    "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, TimeDistributed\n",
    "from keras.layers import Flatten, Dense, Input, Conv2D, MaxPooling2D, Dropout\n",
    "\n",
    "if K.image_dim_ordering() == 'th':\n",
    "\tinput_shape_img = (3, None, None)\n",
    "else:\n",
    "\tinput_shape_img = (400, 400, 3)\n",
    "\n",
    "img_input = Input(shape=input_shape_img)\n",
    "roi_input = Input(shape=(6, 4))\n",
    "nb_classes = 575\n",
    "\n",
    "#pdb.set_trace()\n",
    "num_rois = 6\n",
    "# compile times on theano tend to be very high, so we use smaller ROI pooling regions to workaround\n",
    "\n",
    "if K.backend() == 'tensorflow':\n",
    "    pooling_regions = 4\n",
    "    input_shape = (num_rois,4,4,512)\n",
    "elif K.backend() == 'theano':\n",
    "    pooling_regions = 7\n",
    "    input_shape = (num_rois,512,7,7)\n",
    "\n",
    "# define the base network (resnet here, can be VGG, Inception, etc)\n",
    "shared_layers = nn.nn_base(img_input, trainable=True)\n",
    "\n",
    "\n",
    "out_roi_pool = mylayer(pooling_regions, 6)([shared_layers, roi_input])\n",
    "print out_roi_pool\n",
    "\n",
    "out = (Flatten(name='flatten'))(out_roi_pool)\n",
    "out = (Dense(4096, activation='relu', name='fc5'))(out)\n",
    "out = (Dropout(0.5))(out)\n",
    "out = (Dense(2048, activation='relu', name='fc6'))(out)\n",
    "#out = (Dropout(0.5))(out)\n",
    "#out = (Dense(512, activation='relu', name='fc7'))(out)\n",
    "out_class = (Dense(1000, activation='sigmoid'))(out)\n",
    "\n",
    "model_classifier = Model([img_input, roi_input], out_class)\n",
    "\n",
    "\n",
    "try:\n",
    "\tprint('loading weights from pretrained model')\n",
    "\tmodel_classifier.load_weights('vgg16_weights_tf_dim_ordering_tf_kernels.h5', by_name=True)\n",
    "except:\n",
    "\tprint('Could not load pretrained model weights. Weights can be found in the keras application folder \\\n",
    "\t\thttps://github.com/fchollet/keras/tree/master/keras/applications')\n",
    "\n",
    "optimizer = Adam(lr=1e-5)\n",
    "optimizer_classifier = Adam(lr=1e-5)\n",
    "model_classifier.compile(optimizer=optimizer_classifier, loss = 'binary_crossentropy', metrics= ['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name(x):\n",
    "    name = str.split(x,'/')\n",
    "    return '/Users/1024329/Downloads/DeepFashion/img_n/' + name[1] + '/' + name[2]\n",
    "    \n",
    "df3 = pd.read_pickle('upper_body_atts.pkl')\n",
    "df3['img_name'] = df3['img_name'].apply(lambda x:name(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>landmarks</th>\n",
       "      <th>atts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/1024329/Downloads/DeepFashion/img_n/Lon...</td>\n",
       "      <td>[[96, 2, 60, 60], [165, 2, 60, 60], [300, 153,...</td>\n",
       "      <td>[99, 495, 571, 881, 940]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/1024329/Downloads/DeepFashion/img_n/Hoo...</td>\n",
       "      <td>[[105, 5, 60, 60], [255, 3, 60, 60], [26, 195,...</td>\n",
       "      <td>[470, 953]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/1024329/Downloads/DeepFashion/img_n/Rea...</td>\n",
       "      <td>[[126, 36, 60, 60], [244, 42, 60, 60], [67, 3,...</td>\n",
       "      <td>[745, 883]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/1024329/Downloads/DeepFashion/img_n/Flo...</td>\n",
       "      <td>[[67, 8, 60, 60], [217, 2, 60, 60], [24, 167, ...</td>\n",
       "      <td>[142, 306, 365]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/1024329/Downloads/DeepFashion/img_n/Bea...</td>\n",
       "      <td>[[51, 68, 60, 60], [280, 80, 60, 60], [25, 13,...</td>\n",
       "      <td>[50, 121, 122, 226, 681]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_name  \\\n",
       "0  /Users/1024329/Downloads/DeepFashion/img_n/Lon...   \n",
       "1  /Users/1024329/Downloads/DeepFashion/img_n/Hoo...   \n",
       "2  /Users/1024329/Downloads/DeepFashion/img_n/Rea...   \n",
       "3  /Users/1024329/Downloads/DeepFashion/img_n/Flo...   \n",
       "4  /Users/1024329/Downloads/DeepFashion/img_n/Bea...   \n",
       "\n",
       "                                           landmarks                      atts  \n",
       "0  [[96, 2, 60, 60], [165, 2, 60, 60], [300, 153,...  [99, 495, 571, 881, 940]  \n",
       "1  [[105, 5, 60, 60], [255, 3, 60, 60], [26, 195,...                [470, 953]  \n",
       "2  [[126, 36, 60, 60], [244, 42, 60, 60], [67, 3,...                [745, 883]  \n",
       "3  [[67, 8, 60, 60], [217, 2, 60, 60], [24, 167, ...           [142, 306, 365]  \n",
       "4  [[51, 68, 60, 60], [280, 80, 60, 60], [25, 13,...  [50, 121, 122, 226, 681]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df3[['img_name','landmarks','atts']]\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the samples without any attribute present in it\n",
    "sample = df3['atts'].apply(lambda x: x.shape[0]>0)\n",
    "df4 =df3[sample]\n",
    "df4.shape, df3.shape\n",
    "# checking the maximum value of the attribute label\n",
    "df4['atts'].apply(lambda x: np.max(x)).max()\n",
    "\n",
    "# reset index of df4\n",
    "df4 = df4.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(num):\n",
    "    img = []\n",
    "    landmarks = []\n",
    "    attribs = []\n",
    "    b_size = 32\n",
    "    for i in range(b_size*num, b_size*(num+1)):\n",
    "        #print i\n",
    "        a = cv2.imread(df4.loc[i,'img_name'])\n",
    "        a = cv2.resize(a,(400,400))\n",
    "        a = np.array(a).reshape(400,400,3)\n",
    "        img.append(a/255)\n",
    "        lnd = df4.loc[i,'landmarks']\n",
    "        landmarks.append(lnd)\n",
    "        atts = df4.loc[i,'atts']\n",
    "        labels = np.array([0 if item not in atts else 1 for item in range(1000)]).reshape(1000,)\n",
    "        attribs.append(labels)\n",
    "    return np.array(img), (np.array(landmarks)/8).astype(int), np.array(attribs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = get_batch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18,  0,  7,  7],\n",
       "       [27,  1,  7,  7],\n",
       "       [ 3, 31,  7,  7],\n",
       "       [37, 26,  7,  7],\n",
       "       [10, 43,  7,  6],\n",
       "       [28, 44,  7,  5]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 400, 400, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 400, 400, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 400, 400, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 200, 200, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 200, 200, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 200, 200, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 100, 100, 128 0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 100, 100, 256 295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 100, 100, 256 590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 100, 100, 256 590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 50, 50, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 50, 50, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 50, 50, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 50, 50, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 25, 25, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 25, 25, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 25, 25, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 25, 25, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 12, 12, 512)  0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 6, 4)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mylayer_1 (mylayer)             (None, 6, 4, 4, 512) 0           block5_pool[0][0]                \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 49152)        0           mylayer_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fc5 (Dense)                     (None, 4096)         201330688   flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 4096)         0           fc5[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "fc6 (Dense)                     (None, 2048)         8390656     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1000)         2049000     fc6[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 226,485,032\n",
      "Trainable params: 226,485,032\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 0\n",
      "epoch and sample: 0 0\n",
      "Epoch 1/1\n",
      " - 88s - loss: 0.7732 - acc: 0.4614\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "# train_acc = []\n",
    "for j in range(50):\n",
    "    print 'epoch number:', j\n",
    "    los = 0\n",
    "    acc = 0\n",
    "    for i in range(2000):\n",
    "        if i % 1000 ==0: print 'epoch and sample:', j, i\n",
    "        X,X2,Y = get_batch(i)\n",
    "        history = model_classifier.fit(x=[X,X2], y= Y, verbose = 2)\n",
    "        los = los + np.array(history.history['loss'])\n",
    "        #acc = acc + np.array(history.history['acc'])\n",
    "        #print los\n",
    "    train_loss.append(los)\n",
    "    model_classifier.save_weights('roi_atts.h5')\n",
    "    #train_acc.append(acc)\n",
    "    print train_loss, train_acc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "xa,xb,ya = get_batch_new(10)\n",
    "out_att = model_classifier.predict([xa,xb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfq = pd.read_csv('/Users/1024329/Downloads/DeepFashion/processed_data/list_attr_cloth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.hist(dfq['att_type'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0]), array([30])) (array([0, 0, 0, 0]), array([ 9, 18, 22, 31]))\n"
     ]
    }
   ],
   "source": [
    "print np.nonzero(ya>0), np.nonzero(out_att > 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>landmarks</th>\n",
       "      <th>atts</th>\n",
       "      <th>select46_atts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/1024329/Downloads/DeepFashion/img_n/Lon...</td>\n",
       "      <td>[[96, 2, 60, 60], [165, 2, 60, 60], [300, 153,...</td>\n",
       "      <td>[99, 495, 571, 881, 940]</td>\n",
       "      <td>[495, 571]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/1024329/Downloads/DeepFashion/img_n/Hoo...</td>\n",
       "      <td>[[105, 5, 60, 60], [255, 3, 60, 60], [26, 195,...</td>\n",
       "      <td>[470, 953]</td>\n",
       "      <td>[470]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/1024329/Downloads/DeepFashion/img_n/Rea...</td>\n",
       "      <td>[[126, 36, 60, 60], [244, 42, 60, 60], [67, 3,...</td>\n",
       "      <td>[745, 883]</td>\n",
       "      <td>[745, 883]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/1024329/Downloads/DeepFashion/img_n/Flo...</td>\n",
       "      <td>[[67, 8, 60, 60], [217, 2, 60, 60], [24, 167, ...</td>\n",
       "      <td>[142, 306, 365]</td>\n",
       "      <td>[142, 365]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/1024329/Downloads/DeepFashion/img_n/Bea...</td>\n",
       "      <td>[[51, 68, 60, 60], [280, 80, 60, 60], [25, 13,...</td>\n",
       "      <td>[50, 121, 122, 226, 681]</td>\n",
       "      <td>[226]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_name  \\\n",
       "0  /Users/1024329/Downloads/DeepFashion/img_n/Lon...   \n",
       "1  /Users/1024329/Downloads/DeepFashion/img_n/Hoo...   \n",
       "2  /Users/1024329/Downloads/DeepFashion/img_n/Rea...   \n",
       "3  /Users/1024329/Downloads/DeepFashion/img_n/Flo...   \n",
       "4  /Users/1024329/Downloads/DeepFashion/img_n/Bea...   \n",
       "\n",
       "                                           landmarks  \\\n",
       "0  [[96, 2, 60, 60], [165, 2, 60, 60], [300, 153,...   \n",
       "1  [[105, 5, 60, 60], [255, 3, 60, 60], [26, 195,...   \n",
       "2  [[126, 36, 60, 60], [244, 42, 60, 60], [67, 3,...   \n",
       "3  [[67, 8, 60, 60], [217, 2, 60, 60], [24, 167, ...   \n",
       "4  [[51, 68, 60, 60], [280, 80, 60, 60], [25, 13,...   \n",
       "\n",
       "                       atts select46_atts  \n",
       "0  [99, 495, 571, 881, 940]    [495, 571]  \n",
       "1                [470, 953]         [470]  \n",
       "2                [745, 883]    [745, 883]  \n",
       "3           [142, 306, 365]    [142, 365]  \n",
       "4  [50, 121, 122, 226, 681]         [226]  "
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='min', period=1)\n",
    "# model_classifier.fit(x = [X,X2],y= Y, batch_size=1, epochs=2,validation_split=0.2,callbacks = [checkpoint])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
