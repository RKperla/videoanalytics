{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import random\n",
    "import pprint\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import pickle\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras_frcnn import config, data_generators\n",
    "from keras_frcnn import losses as losses\n",
    "import keras_frcnn.roi_helpers as roi_helpers\n",
    "from keras.utils import generic_utils\n",
    "from keras_frcnn.mylayer import mylayer\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "\n",
    "K.set_learning_phase(1) #set learning phase\n",
    "\n",
    "# sys.setrecursionlimit(40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "network ='vgg'\n",
    "\n",
    "if network == 'vgg':\n",
    "\tfrom keras_frcnn import vgg as nn\n",
    "elif network == 'resnet50':\n",
    "\tfrom keras_frcnn import resnet as nn\n",
    "else:\n",
    "\tprint('Not a valid model')\n",
    "\traise ValueError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Tensor(\"mylayer_1/Reshape:0\", shape=(1, 6, 4, 4, 512), dtype=float32)\n",
      "WARNING:tensorflow:From /anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "loading weights from pretrained model\n"
     ]
    }
   ],
   "source": [
    "from keras_frcnn.RoiPoolingConv import RoiPoolingConv\n",
    "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, TimeDistributed\n",
    "from keras.layers import Flatten, Dense, Input, Conv2D, MaxPooling2D, Dropout\n",
    "\n",
    "if K.image_dim_ordering() == 'th':\n",
    "\tinput_shape_img = (3, None, None)\n",
    "else:\n",
    "\tinput_shape_img = (400, 400, 3)\n",
    "\n",
    "img_input = Input(shape=input_shape_img)\n",
    "roi_input = Input(shape=(6, 4))\n",
    "nb_classes = 575\n",
    "\n",
    "#pdb.set_trace()\n",
    "num_rois = 6\n",
    "# compile times on theano tend to be very high, so we use smaller ROI pooling regions to workaround\n",
    "\n",
    "if K.backend() == 'tensorflow':\n",
    "    pooling_regions = 4\n",
    "    input_shape = (num_rois,4,4,512)\n",
    "elif K.backend() == 'theano':\n",
    "    pooling_regions = 7\n",
    "    input_shape = (num_rois,512,7,7)\n",
    "\n",
    "# define the base network (resnet here, can be VGG, Inception, etc)\n",
    "shared_layers = nn.nn_base(img_input, trainable=True)\n",
    "\n",
    "\n",
    "out_roi_pool = mylayer(pooling_regions, 6)([shared_layers, roi_input])\n",
    "print out_roi_pool\n",
    "\n",
    "out = (Flatten(name='flatten'))(out_roi_pool)\n",
    "out = (Dense(4096, activation='relu', name='fc5'))(out)\n",
    "out = (Dropout(0.5))(out)\n",
    "out = (Dense(2048, activation='relu', name='fc6'))(out)\n",
    "out = (Dropout(0.5))(out)\n",
    "out = (Dense(512, activation='relu', name='fc7'))(out)\n",
    "out_class = (Dense(46, activation='sigmoid', kernel_initializer='zero'))(out)\n",
    "\n",
    "model_classifier = Model([img_input, roi_input], out_class)\n",
    "\n",
    "\n",
    "try:\n",
    "\tprint('loading weights from pretrained model')\n",
    "\tmodel_classifier.load_weights('vgg16_weights_tf_dim_ordering_tf_kernels.h5', by_name=True)\n",
    "except:\n",
    "\tprint('Could not load pretrained model weights. Weights can be found in the keras application folder \\\n",
    "\t\thttps://github.com/fchollet/keras/tree/master/keras/applications')\n",
    "\n",
    "optimizer = Adam(lr=1e-5)\n",
    "optimizer_classifier = Adam(lr=1e-5)\n",
    "model_classifier.compile(optimizer=optimizer_classifier, loss = 'binary_crossentropy', metrics= ['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name(x):\n",
    "    name = str.split(x,'/')\n",
    "    return '/Users/1024329/Downloads/DeepFashion/img_n/' + name[1] + '/' + name[2]\n",
    "    \n",
    "df3 = pd.read_pickle('upper_body_atts.pkl')\n",
    "df3['img_name'] = df3['img_name'].apply(lambda x:name(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>landmarks</th>\n",
       "      <th>atts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/1024329/Downloads/DeepFashion/img_n/Lon...</td>\n",
       "      <td>[[96, 2, 60, 60], [165, 2, 60, 60], [300, 153,...</td>\n",
       "      <td>[99, 495, 571, 881, 940]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/1024329/Downloads/DeepFashion/img_n/Hoo...</td>\n",
       "      <td>[[105, 5, 60, 60], [255, 3, 60, 60], [26, 195,...</td>\n",
       "      <td>[470, 953]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/1024329/Downloads/DeepFashion/img_n/Rea...</td>\n",
       "      <td>[[126, 36, 60, 60], [244, 42, 60, 60], [67, 3,...</td>\n",
       "      <td>[745, 883]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/1024329/Downloads/DeepFashion/img_n/Flo...</td>\n",
       "      <td>[[67, 8, 60, 60], [217, 2, 60, 60], [24, 167, ...</td>\n",
       "      <td>[142, 306, 365]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/1024329/Downloads/DeepFashion/img_n/Bea...</td>\n",
       "      <td>[[51, 68, 60, 60], [280, 80, 60, 60], [25, 13,...</td>\n",
       "      <td>[50, 121, 122, 226, 681]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_name  \\\n",
       "0  /Users/1024329/Downloads/DeepFashion/img_n/Lon...   \n",
       "1  /Users/1024329/Downloads/DeepFashion/img_n/Hoo...   \n",
       "2  /Users/1024329/Downloads/DeepFashion/img_n/Rea...   \n",
       "3  /Users/1024329/Downloads/DeepFashion/img_n/Flo...   \n",
       "4  /Users/1024329/Downloads/DeepFashion/img_n/Bea...   \n",
       "\n",
       "                                           landmarks                      atts  \n",
       "0  [[96, 2, 60, 60], [165, 2, 60, 60], [300, 153,...  [99, 495, 571, 881, 940]  \n",
       "1  [[105, 5, 60, 60], [255, 3, 60, 60], [26, 195,...                [470, 953]  \n",
       "2  [[126, 36, 60, 60], [244, 42, 60, 60], [67, 3,...                [745, 883]  \n",
       "3  [[67, 8, 60, 60], [217, 2, 60, 60], [24, 167, ...           [142, 306, 365]  \n",
       "4  [[51, 68, 60, 60], [280, 80, 60, 60], [25, 13,...  [50, 121, 122, 226, 681]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df3[['img_name','landmarks','atts']]\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "another 1000 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img = []\n",
    "landmarks = []\n",
    "attribs = []\n",
    "for i in range(30):\n",
    "    if i%1000 == 0:\n",
    "        print 'another 1000', i \n",
    "    a = cv2.imread(df3.loc[i,'img_name'])\n",
    "    a = cv2.resize(a,(400,400))\n",
    "    img.append(a)\n",
    "    lnd = df3.loc[i,'landmarks']\n",
    "    landmarks.append(lnd)\n",
    "    atts = df3.loc[i,'atts']\n",
    "    attribs.append(atts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the samples without any attribute present in it\n",
    "sample = df3['atts'].apply(lambda x: x.shape[0]>0)\n",
    "df4 =df3[sample]\n",
    "df4.shape, df3.shape\n",
    "# checking the maximum value of the attribute label\n",
    "df4['atts'].apply(lambda x: np.max(x)).max()\n",
    "\n",
    "# reset index of df4\n",
    "df4 = df4.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# mlb = MultiLabelBinarizer()\n",
    "\n",
    "# X = np.array(img)\n",
    "# X2 = np.array(landmarks)\n",
    "# Y = mlb.fit_transform(attribs)\n",
    "# X2 = (X2/4).astype(int)\n",
    "# print 'shapes of input and output', X.shape, X2.shape, Y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132290, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n"
     ]
    }
   ],
   "source": [
    "vals = np.array([])\n",
    "for i in range(df4.shape[0]):\n",
    "    if i%10000 ==0: print i\n",
    "    vals = np.concatenate([vals,df4.loc[i,'atts']]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "his = plt.hist(vals,bins =1000)\n",
    "select =  np.nonzero(his[0] > 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(vals,bins =1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.nonzero(his[0]>1000))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selecting(x,select):\n",
    "    s = [i for i in x if i in (select[0])]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['select46_atts'] = df4['atts'].apply(lambda x: selecting(x,select))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>landmarks</th>\n",
       "      <th>atts</th>\n",
       "      <th>select46_atts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/1024329/Downloads/DeepFashion/img_n/Lon...</td>\n",
       "      <td>[[96, 2, 60, 60], [165, 2, 60, 60], [300, 153,...</td>\n",
       "      <td>[99, 495, 571, 881, 940]</td>\n",
       "      <td>[495, 571]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/1024329/Downloads/DeepFashion/img_n/Hoo...</td>\n",
       "      <td>[[105, 5, 60, 60], [255, 3, 60, 60], [26, 195,...</td>\n",
       "      <td>[470, 953]</td>\n",
       "      <td>[470]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/1024329/Downloads/DeepFashion/img_n/Rea...</td>\n",
       "      <td>[[126, 36, 60, 60], [244, 42, 60, 60], [67, 3,...</td>\n",
       "      <td>[745, 883]</td>\n",
       "      <td>[745, 883]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/1024329/Downloads/DeepFashion/img_n/Flo...</td>\n",
       "      <td>[[67, 8, 60, 60], [217, 2, 60, 60], [24, 167, ...</td>\n",
       "      <td>[142, 306, 365]</td>\n",
       "      <td>[142, 365]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/1024329/Downloads/DeepFashion/img_n/Bea...</td>\n",
       "      <td>[[51, 68, 60, 60], [280, 80, 60, 60], [25, 13,...</td>\n",
       "      <td>[50, 121, 122, 226, 681]</td>\n",
       "      <td>[226]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_name  \\\n",
       "0  /Users/1024329/Downloads/DeepFashion/img_n/Lon...   \n",
       "1  /Users/1024329/Downloads/DeepFashion/img_n/Hoo...   \n",
       "2  /Users/1024329/Downloads/DeepFashion/img_n/Rea...   \n",
       "3  /Users/1024329/Downloads/DeepFashion/img_n/Flo...   \n",
       "4  /Users/1024329/Downloads/DeepFashion/img_n/Bea...   \n",
       "\n",
       "                                           landmarks  \\\n",
       "0  [[96, 2, 60, 60], [165, 2, 60, 60], [300, 153,...   \n",
       "1  [[105, 5, 60, 60], [255, 3, 60, 60], [26, 195,...   \n",
       "2  [[126, 36, 60, 60], [244, 42, 60, 60], [67, 3,...   \n",
       "3  [[67, 8, 60, 60], [217, 2, 60, 60], [24, 167, ...   \n",
       "4  [[51, 68, 60, 60], [280, 80, 60, 60], [25, 13,...   \n",
       "\n",
       "                       atts select46_atts  \n",
       "0  [99, 495, 571, 881, 940]    [495, 571]  \n",
       "1                [470, 953]         [470]  \n",
       "2                [745, 883]    [745, 883]  \n",
       "3           [142, 306, 365]    [142, 365]  \n",
       "4  [50, 121, 122, 226, 681]         [226]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the samples without any attribute present in it\n",
    "sample = df4['select46_atts'].apply(lambda x: np.array(x).shape[0]>0)\n",
    "df5 =df4[sample]\n",
    "df5.shape, df4.shape\n",
    "# checking the maximum value of the attribute label\n",
    "df5['select46_atts'].apply(lambda x: np.max(x)).max()\n",
    "\n",
    "# reset index of df4\n",
    "df5 = df5.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "vals_new = np.array([])\n",
    "for i in range(df5.shape[0]):\n",
    "    if i %10000==0: print i\n",
    "    vals_new = np.concatenate([vals_new,df5.loc[i,'select46_atts']]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if i % 1000 ==0: print 'epoch and sample:', j, i\n",
    "# X,X2,Y = get_batch(i)\n",
    "# history = model_classifier.fit(x=[X,X2], y= Y)\n",
    "# los = los + np.array(history.history['loss'])\n",
    "# acc = acc + np.array(history.history['acc'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5['select46_atts'] = df5['select46_atts'].apply(lambda x: np.array(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(i):\n",
    "    a = cv2.imread(df4.loc[i,'img_name'])\n",
    "    a = cv2.resize(a,(400,400))\n",
    "    img = np.array(a).reshape(1,400,400,3)\n",
    "    lnd = df4.loc[i,'landmarks']\n",
    "    landmarks = (np.array(lnd)/8).astype(int).reshape(1,6,4)\n",
    "    atts = df4.loc[i,'atts']\n",
    "    labels = np.array([0 if k not in atts else 1 for k in range(1000)]).reshape(1,1000)\n",
    "    return img, landmarks, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,  93, 112, 142, 162, 181, 196, 207, 212, 226, 227, 254, 310,\n",
       "       335, 365, 380, 441, 470, 495, 513, 546, 568, 571, 574, 577, 601,\n",
       "       640, 695, 705, 720, 730, 745, 751, 754, 760, 818, 822, 836, 837,\n",
       "       883, 884, 892, 935, 956, 983, 993])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_new(num):\n",
    "    #print num\n",
    "    a = cv2.imread(df5.loc[num,'img_name'])\n",
    "    a = cv2.resize(a,(400,400))\n",
    "    img = np.array(a).reshape(1,400,400,3)\n",
    "    lnd = df5.loc[num,'landmarks']\n",
    "    landmarks = (np.array(lnd)/8).astype(int).reshape(1,6,4)\n",
    "    atts = df5.loc[num,'select46_atts']\n",
    "    labels = np.array([0 if item not in atts else 1 for item in select[0]]).reshape(1,46)\n",
    "    return img/255, landmarks, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,  93, 112, 142, 162, 181, 196, 207, 212, 226, 227, 254, 310,\n",
       "       335, 365, 380, 441, 470, 495, 513, 546, 568, 571, 574, 577, 601,\n",
       "       640, 695, 705, 720, 730, 745, 751, 754, 760, 818, 822, 836, 837,\n",
       "       883, 884, 892, 935, 956, 983, 993])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 0\n",
      "epoch and sample: 0 0\n",
      "Epoch 1/1\n",
      " - 26s - loss: 0.6931 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.6926 - acc: 0.9348\n",
      "Epoch 1/1\n",
      " - 12s - loss: 0.6921 - acc: 0.9130\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.6916 - acc: 0.9130\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.6903 - acc: 0.9783\n",
      "Epoch 1/1\n",
      " - 13s - loss: 0.6898 - acc: 0.9783\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.6894 - acc: 0.9130\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.6883 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.6879 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.6859 - acc: 0.9565\n",
      "epoch number: 1\n",
      "epoch and sample: 1 0\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.6857 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.6828 - acc: 0.9783\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.6817 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.6789 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.6756 - acc: 0.9783\n",
      "Epoch 1/1\n",
      " - 8s - loss: 0.6763 - acc: 0.9783\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.6751 - acc: 0.9130\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.6689 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.6701 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.6628 - acc: 0.9565\n",
      "epoch number: 2\n",
      "epoch and sample: 2 0\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.6560 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.6525 - acc: 0.9783\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.6485 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 8s - loss: 0.6320 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 8s - loss: 0.6301 - acc: 0.9783\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.6264 - acc: 0.9783\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.6104 - acc: 0.9130\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.5887 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.5747 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.5436 - acc: 0.9565\n",
      "epoch number: 3\n",
      "epoch and sample: 3 0\n",
      "Epoch 1/1\n",
      " - 8s - loss: 0.4986 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 8s - loss: 0.4728 - acc: 0.9783\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.3954 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.3680 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.2781 - acc: 0.9783\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.2542 - acc: 0.9783\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.2735 - acc: 0.9130\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.2142 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 8s - loss: 0.1590 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.1398 - acc: 0.9565\n",
      "epoch number: 4\n",
      "epoch and sample: 4 0\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.1155 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.1175 - acc: 0.9783\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.2295 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.2700 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.1015 - acc: 0.9783\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.0543 - acc: 0.9783\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.4951 - acc: 0.9130\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.2224 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 8s - loss: 0.1463 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 8s - loss: 0.1347 - acc: 0.9565\n",
      "epoch number: 5\n",
      "epoch and sample: 5 0\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.0961 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.0974 - acc: 0.9783\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.1465 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.1658 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.0739 - acc: 0.9783\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.0770 - acc: 0.9783\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.2403 - acc: 0.9130\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1677 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 8s - loss: 0.1313 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.1274 - acc: 0.9565\n",
      "epoch number: 6\n",
      "epoch and sample: 6 0\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.1147 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.1105 - acc: 0.9783\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.1320 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1574 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.0740 - acc: 0.9783\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.0742 - acc: 0.9783\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.2292 - acc: 0.9130\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.1599 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.1105 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.1180 - acc: 0.9565\n",
      "epoch number: 7\n",
      "epoch and sample: 7 0\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.0868 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.1032 - acc: 0.9783\n",
      "Epoch 1/1\n",
      " - 8s - loss: 0.1282 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.1560 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 8s - loss: 0.0699 - acc: 0.9783\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.0537 - acc: 0.9783\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.2521 - acc: 0.9130\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.1619 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 8s - loss: 0.1039 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 8s - loss: 0.1167 - acc: 0.9565\n",
      "epoch number: 8\n",
      "epoch and sample: 8 0\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.0840 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 8s - loss: 0.0951 - acc: 0.9783\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.1358 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.1555 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.0698 - acc: 0.9783\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.0563 - acc: 0.9783\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.2307 - acc: 0.9130\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.1548 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 11s - loss: 0.1042 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.1163 - acc: 0.9565\n",
      "epoch number: 9\n",
      "epoch and sample: 9 0\n",
      "Epoch 1/1\n",
      " - 10s - loss: 0.0923 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.0994 - acc: 0.9783\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.1226 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.1505 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.0660 - acc: 0.9783\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.0608 - acc: 0.9783\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.2261 - acc: 0.9130\n",
      "Epoch 1/1\n",
      " - 8s - loss: 0.1515 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 8s - loss: 0.1025 - acc: 0.9565\n",
      "Epoch 1/1\n",
      " - 9s - loss: 0.1167 - acc: 0.9565\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "# train_acc = []\n",
    "for j in range(20):\n",
    "    print 'epoch number:', j\n",
    "    los = 0\n",
    "    acc = 0\n",
    "    for i in range(2000):\n",
    "        if i % 1000 ==0: print 'epoch and sample:', j, i\n",
    "        X,X2,Y = get_batch_new(i)\n",
    "        history = model_classifier.fit(x=[X,X2], y= Y, verbose = 2)\n",
    "        los = los + np.array(history.history['loss'])\n",
    "        #acc = acc + np.array(history.history['acc'])\n",
    "        #print los\n",
    "    train_loss.append(los)\n",
    "    model_classifier.save_weights('atts_46model.h5')\n",
    "    #train_acc.append(acc)\n",
    "    #print train_loss, train_acc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "xa,xb,ya = get_batch_new(10)\n",
    "out_att = model_classifier.predict([xa,xb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0]), array([30])) (array([0, 0, 0, 0]), array([ 9, 18, 22, 31]))\n"
     ]
    }
   ],
   "source": [
    "print np.nonzero(ya>0), np.nonzero(out_att > 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>landmarks</th>\n",
       "      <th>atts</th>\n",
       "      <th>select46_atts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/1024329/Downloads/DeepFashion/img_n/Lon...</td>\n",
       "      <td>[[96, 2, 60, 60], [165, 2, 60, 60], [300, 153,...</td>\n",
       "      <td>[99, 495, 571, 881, 940]</td>\n",
       "      <td>[495, 571]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/1024329/Downloads/DeepFashion/img_n/Hoo...</td>\n",
       "      <td>[[105, 5, 60, 60], [255, 3, 60, 60], [26, 195,...</td>\n",
       "      <td>[470, 953]</td>\n",
       "      <td>[470]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/1024329/Downloads/DeepFashion/img_n/Rea...</td>\n",
       "      <td>[[126, 36, 60, 60], [244, 42, 60, 60], [67, 3,...</td>\n",
       "      <td>[745, 883]</td>\n",
       "      <td>[745, 883]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/1024329/Downloads/DeepFashion/img_n/Flo...</td>\n",
       "      <td>[[67, 8, 60, 60], [217, 2, 60, 60], [24, 167, ...</td>\n",
       "      <td>[142, 306, 365]</td>\n",
       "      <td>[142, 365]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/1024329/Downloads/DeepFashion/img_n/Bea...</td>\n",
       "      <td>[[51, 68, 60, 60], [280, 80, 60, 60], [25, 13,...</td>\n",
       "      <td>[50, 121, 122, 226, 681]</td>\n",
       "      <td>[226]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_name  \\\n",
       "0  /Users/1024329/Downloads/DeepFashion/img_n/Lon...   \n",
       "1  /Users/1024329/Downloads/DeepFashion/img_n/Hoo...   \n",
       "2  /Users/1024329/Downloads/DeepFashion/img_n/Rea...   \n",
       "3  /Users/1024329/Downloads/DeepFashion/img_n/Flo...   \n",
       "4  /Users/1024329/Downloads/DeepFashion/img_n/Bea...   \n",
       "\n",
       "                                           landmarks  \\\n",
       "0  [[96, 2, 60, 60], [165, 2, 60, 60], [300, 153,...   \n",
       "1  [[105, 5, 60, 60], [255, 3, 60, 60], [26, 195,...   \n",
       "2  [[126, 36, 60, 60], [244, 42, 60, 60], [67, 3,...   \n",
       "3  [[67, 8, 60, 60], [217, 2, 60, 60], [24, 167, ...   \n",
       "4  [[51, 68, 60, 60], [280, 80, 60, 60], [25, 13,...   \n",
       "\n",
       "                       atts select46_atts  \n",
       "0  [99, 495, 571, 881, 940]    [495, 571]  \n",
       "1                [470, 953]         [470]  \n",
       "2                [745, 883]    [745, 883]  \n",
       "3           [142, 306, 365]    [142, 365]  \n",
       "4  [50, 121, 122, 226, 681]         [226]  "
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='min', period=1)\n",
    "# model_classifier.fit(x = [X,X2],y= Y, batch_size=1, epochs=2,validation_split=0.2,callbacks = [checkpoint])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
