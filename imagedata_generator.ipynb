{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import random\n",
    "import pprint\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import pickle\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras_frcnn import config, data_generators\n",
    "from keras_frcnn import losses as losses\n",
    "import keras_frcnn.roi_helpers as roi_helpers\n",
    "from keras.utils import generic_utils\n",
    "from keras_frcnn.mylayer import mylayer\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "\n",
    "K.set_learning_phase(1) #set learning phase\n",
    "\n",
    "# sys.setrecursionlimit(40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "network ='vgg'\n",
    "\n",
    "if network == 'vgg':\n",
    "\tfrom keras_frcnn import vgg as nn\n",
    "elif network == 'resnet50':\n",
    "\tfrom keras_frcnn import resnet as nn\n",
    "else:\n",
    "\tprint('Not a valid model')\n",
    "\traise ValueError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"mylayer_2/Reshape:0\", shape=(1, 6, 7, 7, 512), dtype=float32)\n",
      "no of classes 575\n",
      "Could not load pretrained model weights. Weights can be found in the keras application folder \t\thttps://github.com/fchollet/keras/tree/master/keras/applications\n"
     ]
    }
   ],
   "source": [
    "from keras_frcnn.RoiPoolingConv import RoiPoolingConv\n",
    "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, TimeDistributed\n",
    "from keras.layers import Flatten, Dense, Input, Conv2D, MaxPooling2D, Dropout\n",
    "\n",
    "if K.image_dim_ordering() == 'th':\n",
    "\tinput_shape_img = (3, None, None)\n",
    "else:\n",
    "\tinput_shape_img = (400, 400, 3)\n",
    "\n",
    "img_input = Input(shape=input_shape_img)\n",
    "roi_input = Input(shape=(6, 4))\n",
    "nb_classes = 575\n",
    "\n",
    "#pdb.set_trace()\n",
    "num_rois = 6\n",
    "# compile times on theano tend to be very high, so we use smaller ROI pooling regions to workaround\n",
    "\n",
    "if K.backend() == 'tensorflow':\n",
    "    pooling_regions = 7\n",
    "    input_shape = (num_rois,7,7,512)\n",
    "elif K.backend() == 'theano':\n",
    "    pooling_regions = 7\n",
    "    input_shape = (num_rois,512,7,7)\n",
    "\n",
    "# define the base network (resnet here, can be VGG, Inception, etc)\n",
    "shared_layers = nn.nn_base(img_input, trainable=True)\n",
    "\n",
    "\n",
    "out_roi_pool = mylayer(pooling_regions, 6)([shared_layers, roi_input])\n",
    "print out_roi_pool\n",
    "\n",
    "out = (Flatten(name='flatten'))(out_roi_pool)\n",
    "out = (Dense(4096, activation='relu', name='fc1'))(out)\n",
    "out = (Dropout(0.5))(out)\n",
    "out = (Dense(2048, activation='relu', name='fc2'))(out)\n",
    "out = (Dropout(0.5))(out)\n",
    "print 'no of classes', nb_classes\n",
    "out_class = (Dense(73, activation='sigmoid', kernel_initializer='zero'))(out)\n",
    "\n",
    "model_classifier = Model([img_input, roi_input], out_class)\n",
    "\n",
    "\n",
    "try:\n",
    "\tprint('loading weights from {}'.format(C.base_net_weights))\n",
    "\tmodel_classifier.load_weights(C.base_net_weights, by_name=True)\n",
    "except:\n",
    "\tprint('Could not load pretrained model weights. Weights can be found in the keras application folder \\\n",
    "\t\thttps://github.com/fchollet/keras/tree/master/keras/applications')\n",
    "\n",
    "optimizer = Adam(lr=1e-5)\n",
    "optimizer_classifier = Adam(lr=1e-5)\n",
    "model_classifier.compile(optimizer=optimizer_classifier, loss = 'binary_crossentropy', metrics= ['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name(x):\n",
    "    name = str.split(x,'/')\n",
    "    return '/Users/1024329/Downloads/DeepFashion/img_n/' + name[1] + '/' + name[2]\n",
    "    \n",
    "df3 = pd.read_pickle('upper_body_atts.pkl')\n",
    "df3['img_name'] = df3['img_name'].apply(lambda x:name(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>landmarks</th>\n",
       "      <th>atts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/1024329/Downloads/DeepFashion/img_n/Lon...</td>\n",
       "      <td>[[96, 2, 60, 60], [165, 2, 60, 60], [300, 153,...</td>\n",
       "      <td>[99, 495, 571, 881, 940]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/1024329/Downloads/DeepFashion/img_n/Hoo...</td>\n",
       "      <td>[[105, 5, 60, 60], [255, 3, 60, 60], [26, 195,...</td>\n",
       "      <td>[470, 953]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/1024329/Downloads/DeepFashion/img_n/Rea...</td>\n",
       "      <td>[[126, 36, 60, 60], [244, 42, 60, 60], [67, 3,...</td>\n",
       "      <td>[745, 883]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/1024329/Downloads/DeepFashion/img_n/Flo...</td>\n",
       "      <td>[[67, 8, 60, 60], [217, 2, 60, 60], [24, 167, ...</td>\n",
       "      <td>[142, 306, 365]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/1024329/Downloads/DeepFashion/img_n/Bea...</td>\n",
       "      <td>[[51, 68, 60, 60], [280, 80, 60, 60], [25, 13,...</td>\n",
       "      <td>[50, 121, 122, 226, 681]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_name  \\\n",
       "0  /Users/1024329/Downloads/DeepFashion/img_n/Lon...   \n",
       "1  /Users/1024329/Downloads/DeepFashion/img_n/Hoo...   \n",
       "2  /Users/1024329/Downloads/DeepFashion/img_n/Rea...   \n",
       "3  /Users/1024329/Downloads/DeepFashion/img_n/Flo...   \n",
       "4  /Users/1024329/Downloads/DeepFashion/img_n/Bea...   \n",
       "\n",
       "                                           landmarks                      atts  \n",
       "0  [[96, 2, 60, 60], [165, 2, 60, 60], [300, 153,...  [99, 495, 571, 881, 940]  \n",
       "1  [[105, 5, 60, 60], [255, 3, 60, 60], [26, 195,...                [470, 953]  \n",
       "2  [[126, 36, 60, 60], [244, 42, 60, 60], [67, 3,...                [745, 883]  \n",
       "3  [[67, 8, 60, 60], [217, 2, 60, 60], [24, 167, ...           [142, 306, 365]  \n",
       "4  [[51, 68, 60, 60], [280, 80, 60, 60], [25, 13,...  [50, 121, 122, 226, 681]  "
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df3[['img_name','landmarks','atts']]\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "another 1000 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img = []\n",
    "landmarks = []\n",
    "attribs = []\n",
    "for i in range(30):\n",
    "    if i%1000 == 0:\n",
    "        print 'another 1000', i \n",
    "    a = cv2.imread(df3.loc[i,'img_name'])\n",
    "    a = cv2.resize(a,(400,400))\n",
    "    img.append(a)\n",
    "    lnd = df3.loc[i,'landmarks']\n",
    "    landmarks.append(lnd)\n",
    "    atts = df3.loc[i,'atts']\n",
    "    attribs.append(atts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes of input and output (30, 400, 400, 3) (30, 6, 4) (30, 73)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "X = np.array(img)\n",
    "X2 = np.array(landmarks)\n",
    "Y = mlb.fit_transform(attribs)\n",
    "X2 = (X2/4).astype(int)\n",
    "print 'shapes of input and output', X.shape, X2.shape, Y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='min', period=1)\n",
    "# model_classifier.fit(x = [X,X2],y= Y, batch_size=1, epochs=10,validation_split=0.2,callbacks = [checkpoint])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
