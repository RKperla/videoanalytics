{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataframe\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import random\n",
    "import pprint\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import pickle\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import pdb\n",
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras_frcnn import config, data_generators\n",
    "from keras_frcnn import losses as losses\n",
    "import keras_frcnn.roi_helpers as roi_helpers\n",
    "from keras.utils import generic_utils\n",
    "from keras_frcnn.mylayer import mylayer\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras_frcnn.RoiPoolingConv import RoiPoolingConv\n",
    "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, TimeDistributed\n",
    "from keras.layers import Flatten, Dense, Input, Conv2D, MaxPooling2D, Dropout\n",
    "\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "session = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "K.set_learning_phase(1) #set learning phase\n",
    "\n",
    "from keras.models import Sequential\n",
    "\"\"\"Import from keras_preprocessing not from keras.preprocessing, because Keras may or maynot contain the features discussed here depending upon when you read this article, until the keras_preprocessed library is updated in Keras use the github version.\"\"\"\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print 'loading dataframe'\n",
    "df = pd.read_pickle(\"./upper_body_atts.pkl\")\n",
    "#df= df[0:10000]\n",
    "df = df[['img_name','landmarks','atts']]\n",
    "\n",
    "df[\"labels\"] = df[\"atts\"].apply(lambda x:list(x))\n",
    "\n",
    "def name(x):\n",
    "    name = str.split(x,'/')\n",
    "    return '/Users/1024329/Downloads/DeepFashion/img_n/'+ name[1]+'/'  + name[2]\n",
    "    #return '/fashion-attribute/storage_bucket/deep_fashion/img_bbox_data/img_n/' + name[1] + '/' + name[2]\n",
    "#/fashion-attribute/storage_bucket/small_data_set/work/train/Blazer/Double-Breasted_Blazer\n",
    "\n",
    "# local path : /Users/1024329/Downloads/DeepFashion/img_n/\n",
    "# server path : /fashion-attribute/storage_bucket/deep_fashion/img_bbox_data/img_n/\n",
    "    \n",
    "df['Filenames'] = df['img_name'].apply(lambda x:name(x))\n",
    "\n",
    "#df['Filenames'] = df['img_name'].apply(lambda x: '/Users/1024329/Downloads/DeepFashion/' + x)\n",
    "\n",
    "# removing the samples without any attribute present in it\n",
    "sample = df['atts'].apply(lambda x: x.shape[0]>0)\n",
    "df4 =df[sample]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = pd.read_csv('/Users/1024329/Downloads/DeepFashion/processed_data/list_attr_cloth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select = np.array(df_cat[df_cat.att_type == 1 ].index)\n",
    "select.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df4['cat1atts'] = df4['labels'].apply(lambda x: [item for item in select if item in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df4['cat1atts'].apply(lambda x: len(x)>0)\n",
    "df5 =df4[sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df5.reset_index(drop= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "vals = np.array([])\n",
    "for i in range(df5.shape[0]):\n",
    "    if i%10000 ==0: print i\n",
    "    vals = np.concatenate([vals,df5.loc[i,'cat1atts']]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.bincount(vals.astype(int))\n",
    "ii = np.nonzero(y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = zip(ii,y[ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = [ i[0] for i in s if i[1] > 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print len(sa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5['cat1atts'] = df5['cat1atts'].apply(lambda x: [item for item in sa if item in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df5['cat1atts'].apply(lambda x: len(x)>0)\n",
    "df5 =df5[sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44163, 6)\n"
     ]
    }
   ],
   "source": [
    "print df5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating image generators\n",
      "Found 37000 validated image filenames belonging to 15 classes.\n",
      "validation generator\n",
      "Found 3000 validated image filenames belonging to 15 classes.\n",
      "test generator\n",
      "Found 4163 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print 'creating image generators'\n",
    "#import pdb\n",
    "#pdb.set_trace()\n",
    "img_reso = 224\n",
    "datagen=ImageDataGenerator(rescale=1./255.)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "train_generator=datagen.flow_from_dataframe(dataframe=df5[0:37000],directory=\"\", \n",
    "        x_col=\"Filenames\",y_col=\"cat1atts\",batch_size=32,\n",
    "        seed=42,shuffle=True,class_mode=\"categorical\",\n",
    "        classes=list(sa),target_size=(img_reso,img_reso))\n",
    "\n",
    "print 'validation generator'\n",
    "valid_generator=test_datagen.flow_from_dataframe(\n",
    "        dataframe=df5[37000:40000],\n",
    "directory=\"\",\n",
    "x_col=\"Filenames\",\n",
    "y_col=\"cat1atts\",\n",
    "batch_size=32,\n",
    "seed=42,\n",
    "shuffle=True,\n",
    "class_mode=\"categorical\",\n",
    "classes=list(sa),\n",
    "target_size=(img_reso,img_reso))\n",
    "\n",
    "print 'test generator'\n",
    "test_generator=test_datagen.flow_from_dataframe(dataframe=df5[40000:],\n",
    "directory=\"\",\n",
    "x_col=\"Filenames\",\n",
    "batch_size=1,\n",
    "seed=42,\n",
    "shuffle=False,\n",
    "class_mode=None,\n",
    "target_size=(img_reso,img_reso))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "loading weights from pretrained model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "network ='vgg'\n",
    "\n",
    "if network == 'vgg':\n",
    "\tfrom keras_frcnn import vgg as nn\n",
    "elif network == 'resnet50':\n",
    "\tfrom keras_frcnn import resnet as nn\n",
    "else:\n",
    "\tprint('Not a valid model')\n",
    "\traise ValueError\n",
    "\n",
    "\n",
    "if K.image_dim_ordering() == 'th':\n",
    "\tinput_shape_img = (3, None, None)\n",
    "else:\n",
    "\tinput_shape_img = (224,224, 3)\n",
    "\n",
    "img_input = Input(shape=input_shape_img)\n",
    "\n",
    "# define the base network (resnet here, can be VGG, Inception, etc)\n",
    "shared_layers = nn.nn_base(img_input, trainable=False)\n",
    "\n",
    "out = (Flatten(name='flatten'))(shared_layers)\n",
    "out = (Dense(4096, activation='relu', name='fc5'))(out)\n",
    "out = (Dropout(0.5))(out)\n",
    "out = (Dense(2048, activation='relu', name='fc6'))(out)\n",
    "out = (Dropout(0.5))(out)\n",
    "out = (Dense(512, activation='relu', name='fc7'))(out)\n",
    "out_class = (Dense(15, activation='sigmoid'))(out)\n",
    "\n",
    "model_classifier = Model(img_input, out_class)\n",
    "\n",
    "try:\n",
    "\tprint('loading weights from pretrained model')\n",
    "# \tmodel_classifier.load_weights('vgg16_weights_tf_dim_ordering_tf_kernels.h5', by_name=True)\n",
    "except:\n",
    "\tprint('Could not load pretrained model weights. Weights can be found in the keras application folder \\\n",
    "\t\thttps://github.com/fchollet/keras/tree/master/keras/applications')\n",
    "\n",
    "model_classifier.compile(optimizers.rmsprop(lr=0.0001, decay=1e-6),loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "# checkpoint = ModelCheckpoint(\"cat1_atts.h5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='min', period=1)\n",
    "\n",
    "\n",
    "# STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "# STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "# STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "# model_classifier.fit_generator(generator=train_generator,\n",
    "#                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "#                    validation_data=valid_generator,\n",
    "#                    validation_steps=STEP_SIZE_VALID,\n",
    "#                    epochs=50, use_multiprocessing=True, callbacks = [checkpoint])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_classifier.load_weights('vgg16_atts.h5')\n",
    "model_classifier.load_weights('cat1_atts.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "# model_f = keras.models.load_model('vgg16_atts.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = train_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 224, 224, 3), (32, 15))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model_classifier.predict(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 15)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35815144, 0.896596  , 0.2668553 , 0.6152868 , 0.5150771 ,\n",
       "       0.27329677, 0.25082582, 0.7354173 , 0.6192313 , 0.3621807 ,\n",
       "       0.59007424, 0.67700815, 0.909754  , 0.52127945, 0.5015631 ,\n",
       "       0.41076994, 0.50224733, 0.8217701 , 0.3069983 , 0.73242825,\n",
       "       0.5389958 , 0.38839337, 0.35896266, 0.51073277, 0.44511095,\n",
       "       0.6747395 , 0.6353736 , 0.41887638, 0.9745019 , 0.19980565,\n",
       "       0.21419835, 0.48014587], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(out,axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([ 3,  4, 10]),), (array([ 3, 10]),))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = 11\n",
    "np.nonzero(out[num,:]> 0.1), np.nonzero(b[num,:] > 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
